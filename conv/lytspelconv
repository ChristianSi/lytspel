#!/usr/bin/python3
"""Convert a file or a text block from tradspell to Lytspel.

Copyright (c) 2018-2019 Christian Siefkes

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
"""


import csv
from inspect import trace
from os import path
import re
from sys import argv, exc_info
from typing import Dict, List, Sequence, TextIO, TypeVar
import warnings
from warnings import warn
from zipfile import is_zipfile, ZipFile

from lxml import etree, html
import spacy


# Constants and type variables
SCRIPTNAME = 'lytspelconv'

LOWERCASE_LETTER_PAT = '[a-záàăâǎåäãąāảæćĉčċçďđéèĕêěëẽęēẻǵğĝǧġḡĥȟḧħíìĭîǐïĩįīĵǰḱǩĺľłḹḿńǹňñóòŏôǒöõøǫōỏœṕŕřśŝšşßťẗúùŭûǔůüũųūủṽẃẁẘẅẍýỳŷẙÿỹȳỷźẑž]'

BLOCK_LEVEL_TAGS = set(('address', 'article', 'aside', 'blockquote', 'canvas', 'dd', 'div',
        'dl', 'dt', 'fieldset', 'figcaption', 'figure', 'footer', 'form', 'h1', 'h2',
        'h3', 'h4', 'h5', 'h6', 'header', 'hr', 'li', 'main', 'nav', 'noscript', 'ol',
        'output', 'p', 'pre', 'section', 'table', 'tfoot', 'ul', 'video'))

T = TypeVar('T')


# Initialization code

if __name__ == '__main__':
    def compact_warning(message, category, filename, lineno, line=None):
        """Print warnings without showing the warning message line itself."""
        fname = path.split(filename)[1]
        return '{}:{}: {}: {}\n'.format(fname, lineno, category.__name__, message)

    warnings.formatwarning = compact_warning


def dict_filename() -> str:
    """Return the name of the dictionary file.

    The file is supposed to sit in a '../data' directory relative to the location of the
    current script.
    """
    script_dir = path.dirname(__file__)
    joined_path = path.join(script_dir, '../data/lytspel-dict.csv')
    return path.abspath(joined_path)  # eliminate '../' part


def is_mixed_case(word: str) -> bool:
    """Test whether a word is MiXed case.

    A word is assumed to be MiXed case if it starts with an upper-case letter and if it
    contains at least one other upper-case and one lower-case letter. Words must be
    ASCII-fied for this function to work correctly.
    """
    return re.match('[A-Z].*[a-z]', word) and re.search('.[A-Z]', word)


def get_elem(seq: Sequence[T], idx: int) -> T:
    """Savely retried an element from a sequence.

    None is returned if 'seq' ends before the requested 'idx' position.
    """
    if len(seq) > idx:
        return seq[idx]
    else:
        return None


def load_dict() -> Dict[str, str]:
    """Load the dictionary.

    Also loads the 'mixed_dict' dictionary which must already exist as an (empty) global.
    """
    with open(dict_filename(), encoding='utf-8') as csvfile:
        csvreader = csv.reader(csvfile)
        next(csvreader)  # skip header line
        result = {}
        redirects = {}  # will be resolved later

        for row in csvreader:
            tradspell = get_elem(row, 0)
            pos = get_elem(row, 1)
            redirect = get_elem(row, 2)
            lytspel = get_elem(row, 3)

            if tradspell and lytspel:
                ts_lower = tradspell.lower()
                ls_lower = lytspel.lower()

                if pos:
                    # Treat value as a dict of POS-tagged entries
                    if not ts_lower in result:
                        result[ts_lower] = {}
                    result[ts_lower][pos] = ls_lower
                else:
                    result[ts_lower] = ls_lower

                if is_mixed_case(lytspel):
                    mixed_dict[tradspell] = lytspel

            elif tradspell and redirect:
                redirects[tradspell.lower()] = redirect.lower()
            else:
                warn('Unexpected/malformed CSV row: {}'.format(','.join(row)))

        # Resolve redirects
        for key, target in redirects.items():
            value = result.get(target)
            if value:
                result[key] = value
            else:
                warn("Target '{}' of redirect '{}' missing!".format(target, key))

        return result


# Globals
mixed_dict = {}
ls_dict = load_dict()
nlp = spacy.load('en')


# Main code

def asciify(word: str) -> str:
    """Convert a word to its ASCII equivalent.

    Typographic apostrophes are replaced by normal ones and diacritical letters are
    replaced by their closest ASCII equivalents.
    """
    result = word.replace('’', "'")  # ASCII-ify apostrophes

    if not re.match("[a-zA-Z']*$", result): # non-ASCII word
        letters = list(result)

        for i, letter in enumerate(letters):
            if ord(letter) < 128: continue  # ASCII, nothing to do
            lower_letter = letter.lower()
            replacement = ''

            # vowels and semivowels
            if lower_letter in 'áàăâǎåäãąāả':
                replacement = 'a'
            elif lower_letter in 'æ':
                replacement = 'ae'
            elif lower_letter in 'éèĕêěëẽęēẻ':
                replacement = 'e'
            elif lower_letter in 'íìĭîǐïĩįī':
                replacement = 'i'
            elif lower_letter in 'óòŏôǒöõøǫōỏ':
                replacement = 'o'
            elif lower_letter in 'œ':
                replacement = 'oe'
            elif lower_letter in 'úùŭûǔůüũųūủ':
                replacement = 'u'
            elif lower_letter in 'ýỳŷẙÿỹȳỷ':
                replacement = 'y'
            # consonants
            elif lower_letter in 'ćĉčċç':
                replacement = 'c'
            elif lower_letter in 'ďđ':
                replacement = 'd'
            elif lower_letter in 'ǵğĝǧġḡ':
                replacement = 'g'
            elif lower_letter in 'ĥȟḧħ':
                replacement = 'h'
            elif lower_letter in 'ĵǰ':
                replacement = 'j'
            elif lower_letter in 'ḱǩ':
                replacement = 'k'
            elif lower_letter in 'ĺľłḹ':
                replacement = 'l'
            elif lower_letter in 'ḿ':
                replacement = 'm'
            elif lower_letter in 'ńǹňñ':
                replacement = 'n'
            elif lower_letter in 'ṕ':
                replacement = 'p'
            elif lower_letter in 'ŕř':
                replacement = 'r'
            elif lower_letter in 'śŝšş':
                replacement = 's'
            elif lower_letter in 'ß':
                replacement = 'ss'
            elif lower_letter in 'ťẗ':
                replacement = 't'
            elif lower_letter in 'ṽ':
                replacement = 'v'
            elif lower_letter in 'ẃẁẘẅ':
                replacement = 'w'
            elif lower_letter in 'ẍ':
                replacement = 'x'
            elif lower_letter in 'źẑž':
                replacement = 'z'

            if replacement:
                if letter != lower_letter:  #  original was upper case
                    replacement = replacement.upper()
                letters[i] = replacement

        result = ''.join(letters)
    return result


def translate_pos(spacy_pos: str) -> str:
    """Translate a POS tag as used by Spacy into the form used in the dictionary."""
    if spacy_pos in ('AUX', 'VERB'):
        return 'v'
    elif spacy_pos in ('NOUN', 'PROPN'):
        return 'n'
    elif spacy_pos == 'ADJ':
        return 'aj'
    elif spacy_pos == 'ADV':
        return 'av'
    elif spacy_pos == 'ADP':
        return 'prp'
    else:
        # Leave other tags as is (shouldn't occur regarding our POS-tagged entries)
        return spacy_pos


def find_pos_tagged_entry(entries: dict, spacy_pos: str) -> str:
    """Find the entry to use if several POS-tagged spellings exist for a word."""
    pos = translate_pos(spacy_pos)
    result = entries.get(pos)

    if result is None:
        # Try suitable fallbacks
        if pos in ('aj', 'av'):
            result = entries.get('v')
        elif pos == 'v':
            result = entries.get('aj')

    if result is None:
        # Use to last (alphabetically) entry as ultimate fallback
        warn("POS tag {} doesn't match any of the entries in {}; using last entry as fallback"
                .format(pos, entries))
        result = entries[sorted(entries.keys())[-1]]

    return result


def lookup(word: str, spacy_pos: str) -> str:
    """Lookup a word in the dictionary and returned its converted form.

    'spacy_pos' is the POS tag as returned by Spacy.

    Case is restored (lower, Capitalized, or ALL_CAPS). MixedCase is also restored
    provided that *both* the input word and the dictionary entry use this case form
    (e.g. JavaScript -> JaavaScript).
    """
    word = asciify(word)
    genitiveS = ''

    if re.search(".'s$", word, re.IGNORECASE):
        # Strip final 's (genitive or contraction) and remember for later (handling case)
        genitiveS = word[-2:]
        word = word[:-2]

    lower = word.lower()

    if lower in ("'ll", "'re", "'ve"):
        # Contraction tokens produced by Spacy: discard the last letter
        result = lower[:-1]
    elif re.match("'.$", lower):
        # Single-letter contraction token: return as is
        result = lower
    else:
        result = ls_dict.get(lower)
        if result is None:
            return result

        if isinstance(result, dict):
            result = find_pos_tagged_entry(result, spacy_pos)

    if re.match("[A-Z']+$", word):
        result = result.upper()  # ALL_CAPS
    elif re.match('[A-Z]', word):
        if word in mixed_dict:
            result = mixed_dict[word]  #  MixedCase
        else:
            result = result[0].upper() + result[1:]  # Capitalized

    if genitiveS:
        result += genitiveS

    result = result.replace( "'", '’')  # replace normal by typographic apostrophe
    return result


def is_word(token: str) -> bool:
    """Check if a token is a word.

    Words start with a letter, or with an apostrophe followed by a letter."""
    return re.match("['’]?" + LOWERCASE_LETTER_PAT, token, re.IGNORECASE)


def convert_para(text: str, make_foreign_lang_text: bool = True) -> str:
    """Convert a paragraph.

    If 'make_foreign_lang_text' is True and a large part of the words in the paragraph is
    unknown, the paragraph is assumed to be written in a foreign language and returned
    unchanged.
    """
    if not text:
        return text  # Empty or None, nothing to do

    doc = nlp(text)
    tokens = []
    known_words = 0
    unknown_words = 0
    lasttok = ''

    for entry in doc:
        token = entry.text
        if token.lower() in ("n't", 'n’t'):
            # Spacy treats n't (as in don't etc.) as a separate word, but we look it up together
            # with the preceding word because the joined pronounciation (and hence spelling)
            # is sometimes different
            if tokens:
                tokens.pop()
            token = lasttok + token

        if is_word(token):
            conv = lookup(token, entry.pos_)
            if conv:
                known_words += 1
                tokens.append(conv)
            else:
                unknown_words += 1
                tokens.append(token)
        else:
            # Not a word: append as is
            tokens.append(token)

        lasttok = token
        # Append trailing whitespace to token, if any
        if entry.whitespace_:
            tokens[-1] += entry.whitespace_

    if not make_foreign_lang_text or unknown_words <= known_words:
        # We shouldn't make the foreign language test OR at least half of the words are known
        return ''.join(tokens)
    else:
        return text  # Return text unchanged


def determine_file_type(filename: str) -> str:
    """Inspect the contents of a file to determine the likely file type.

    Returns either 'epub', 'html', 'txt', or None if the file is clearly not of any of these
    types. However, 'txt' is used as a fairly general fallback hence it's quite possible that
    a file labeled as 'txt' is actually something else
    """
    # Check if it's an epub file
    if is_zipfile(filename):
        with ZipFile(filename) as zip:
            bytes = b''

            try:
                bytes = zip.read('mimetype')
            except KeyError:
                pass  # Not an epub file

            if bytes.decode().startswith('application/epub+zip'):
                return 'epub'
            else:
                return None

    with open(filename) as file:
        for line in file:
            line = line.strip()
            if not line: continue  # Empty line, inspect next one
            if re.match("<[!?h]", line, re.IGNORECASE):
                # File seems to start with a DOCTYPE or XML declaration, HTML comment or
                # <html> tag
                return 'html'
            else:
                break

    return 'txt'


def convert_html_elem(elem: html.HtmlElement) -> None:
    """Recursively convert an element in an HTML document and its children.

    Whether to convert textual content is decided on the level of block-level tags (such
    as 'h1', 'blockquote', 'p') that do NOT contain any directly nested block-level tags
    (e.g. if an 'ol' contains 'li' elements, the decision will be made for each of the
    latter independently, not for the whole 'ol'). If a large part of the text embedded
    in such an element seems to be in a foreign language, the whole element will NOT be
    converted.
    """
    # Check if we should made the foreign-language test as this level
    if elem.tag in BLOCK_LEVEL_TAGS:
        decide_on_conversion = True

        for child in elem:
            if child.tag in BLOCK_LEVEL_TAGS:
                decide_on_conversion = False
                break

        if decide_on_conversion:
            # Ask convert_para as "oracle" whether the textual content looks English or foreign
            full_text = str(elem.text_content())
            if convert_para(full_text) == full_text:
                # Oracle said "foreign", so we skip this part of the document tree
                return

    # Convert immediate content
    elem.text = convert_para(elem.text, False)

    # Convert a few textual attributes, if they are present
    for attrib in ('alt', 'title'):
        if attrib in elem.attrib:
            elem.attrib[attrib] = convert_para(elem.attrib[attrib])

    # Convert child elements (except comments and those that don't contain normal text)
    for child in elem:
        if not (isinstance(child, html.HtmlComment)
                or isinstance(child, html.HtmlProcessingInstruction)
                or child.tag in ('script', 'style')):
            convert_html_elem(child)
        child.tail = convert_para(child.tail, False)


def convert_html_document(filename: str) -> None:
    """Convert a HTML file."""
    with open(filename) as file:
        doc = html.parse(file)
        root = doc.getroot()
        title = root.find('.//title')
        title.text = convert_para(title.text)
        convert_html_elem(root.find('body'))
        print(html.tostring(doc, encoding='utf8').decode('utf8'))


def convert_epub(filename: str) -> None:
    """Convert an epub file.

    If the input file is called 'FILE.epub', the output will be stored in a new file called
    'FILE-lytspel.epub'.
    """
    (root, ext) = path.splitext(filename)
    outfile = '{}-lytspel{}'.format(root, ext)

    with ZipFile(filename, 'r') as zin:
        # Find the contents metafile
        bytes = zin.read('META-INF/container.xml')
        tree = etree.fromstring(bytes)
        opfname = tree.xpath('n:rootfiles/n:rootfile/@full-path',
                namespaces={'n': 'urn:oasis:names:tc:opendocument:xmlns:container'})[0]

        # Find the XML files that need conversion
        bytes = zin.read(opfname)
        tree = etree.fromstring(bytes)
        items = tree.xpath('/p:package/p:manifest/p:item',
                namespaces={'p': 'http://www.idpf.org/2007/opf'})
        for item in items:
            print('file: {}, type: {}'.format(item.attrib['href'], item.attrib['media-type']))
        ## TODO Relevant media types: application/xhtml+xml, application/x-dtbncx+xml (NCX file).

        # Copy files to output archive, converting them if needed
        with ZipFile(outfile, 'w') as zout:
            zout.comment = zin.comment  # Preserve the comment, if any

            for item in zin.infolist():
                # TODO Check if it's one of the files that need conversion
                ##if item.filename != filename:
                zout.writestr(item, zin.read(item.filename))

    print('{}: Output written to {}'.format(SCRIPTNAME, outfile))


def convert_text_document(filename: str) -> None:
    """Convert a plain text file."""
    para = ''

    with open(filename) as file:
        for line in file:
            line = line.rstrip()
            # Paragraphs are considered to be separated by empty lines.
            # However, very long lines (200+ chars) are considered paragraphs in their own right.
            if len(line) >= 200:  # stand-alone paragraph
                if para:
                    print(convert_para(para))
                    para = ''
                print(convert_para(line))
            elif line:            # regular line
                if para:
                    para += '\n'
                para += line
            else:                 # empty line
                if para:
                    print(convert_para(para))
                    para = ''
                print()

        # Convert final paragraph, if any
        if para:
            print(convert_para(para))


def convert_file(filename: str) -> None:
    """Convert the file with the specified name.

    Recognized file types are epub, HTML and plain text.
    """
    file_type = determine_file_type(file)
    if file_type == 'epub':
        convert_epub(file)
    elif file_type == 'html':
        convert_html_document(file)
    elif file_type == 'txt':
        convert_text_document(file)
    elif file_type is None:
        exit('{}: Cannot convert {} (unsupported file type)'.format(SCRIPTNAME, filename))
    else:
        raise ValueError('Unexpected file type: {}'.format(file_type))


if __name__ == '__main__':
    try:
        for file in argv[1:]:
            convert_file(file)
    except Exception as e:
        tb = exc_info()[2]
        # Find highest stack frame in the current file (closest to source of exception)
        frames = trace()
        last_useful_frame = frames[0]
        current_file = last_useful_frame.filename

        for frame in frames[1:]:
            if frame.filename == current_file:
                last_useful_frame = frame
            else:
                break  # Stepping out of current file

        fname = path.split(current_file)[1]
        exit('{}:{}: {}: {}'.format(fname, last_useful_frame.lineno, e.__class__.__name__, e))


# TODO Handle and test:
# * Special case: I and I'm should only remain capitalized at the beginning of sentences
#   (cf. token.is_sent_start: bool, None if unknown)
# * Might require additional POS tag: ‹re› should become  «ri» if used as a hyphenated prefix
# * Might require additional POS tag: US (capitalized) should remain unchanged
# * -u/--unknown Option to list unknown words (with frequency count)
# * Convert module to class.
# * Allow converting text passed on command line (-c flag)
# * Use pylint to check the coding style
# * Add button to turn conversion off and on
# * Also rewrite parts of a page loaded later (e.g. due to scrolling; sample: Youtube
#   comments); possibly use a custom data-\* attribute; can be read and written as
#   elem.dataset.NAME, e.g. elem.dataset.lytspel = conv|seen
# * Accept '-' argument to read stdin (file type recognition should still work)
# * If called w/o arguments open dialog that allows the conversion of local txt/html/epub files,
#   always writing the output to a file
# * Add a dialog for converting words and sentences to Lytspel
# * Package for pip3 and announce to the world
# * Add drag-and-drop support (esp. for Windows)
