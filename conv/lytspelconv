#!/usr/bin/python3
"""Convert a file or a text block from tradspell to Lytspel.

Copyright (c) 2018-2019 Christian Siefkes

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
"""


from typing import Dict, List, Sequence, TypeVar
import csv
from os import path
import re
from sys import argv
from warnings import warn

import spacy


# Constants and type variables
LOWERCASE_LETTER_PAT = '[a-záàăâǎåäãąāảæćĉčċçďđéèĕêěëẽęēẻǵğĝǧġḡĥȟḧħíìĭîǐïĩįīĵǰḱǩĺľłḹḿńǹňñóòŏôǒöõøǫōỏœṕŕřśŝšşßťẗúùŭûǔůüũųūủṽẃẁẘẅẍýỳŷẙÿỹȳỷźẑž]'
TOKEN_RE = re.compile('(' + LOWERCASE_LETTER_PAT + "(?:['’]?" + LOWERCASE_LETTER_PAT +')*)',
        re.IGNORECASE)
STARTS_WITH_LETTER_RE = re.compile('^' + LOWERCASE_LETTER_PAT, re.IGNORECASE)

T = TypeVar('T')


# Initialization code

def dict_filename() -> str:
    """Return the name of the dictionary file.

    The file is supposed to sit in a '../data' directory relative to the location of the
    current script.
    """
    script_dir = path.dirname(__file__)
    joined_path = path.join(script_dir, '../data/lytspel-dict.csv')
    return path.abspath(joined_path)  # eliminate '../' part


def is_mixed_case(word: str) -> bool:
    """Test whether a word is MiXed case.

    A word is assumed to be MiXed case if it starts with an upper-case letter and if it
    contains at least one other upper-case and one lower-case letter. Words must be
    ASCII-fied for this function to work correctly.
    """
    return re.match('[A-Z].*[a-z]', word) and re.search('.[A-Z]', word)


def get_elem(seq: Sequence[T], idx: int) -> T:
    """Savely retried an element from a sequence.

    None is returned if 'seq' ends before the requested 'idx' position.
    """
    if len(seq) > idx:
        return seq[idx]
    else:
        return None


def load_dict() -> Dict[str, str]:
    """Load the dictionary.

    Also loads the 'mixed_dict' dictionary which must already exist as an (empty) global.
    """
    with open(dict_filename(), encoding='utf-8') as csvfile:
        csvreader = csv.reader(csvfile)
        next(csvreader)  # skip header line
        result = {}

        for row in csvreader:
            tradspell = get_elem(row, 0)
            pos = get_elem(row, 1)
            lytspel = get_elem(row, 3)

            if tradspell and lytspel:
                ts_lower = tradspell.lower()
                ls_lower = lytspel.lower()

                if pos:
                    # Treat value as a dict of POS-tagged entries
                    if not ts_lower in result:
                        result[ts_lower] = {}
                    result[ts_lower][pos] = ls_lower
                else:
                    result[ts_lower] = ls_lower

                if is_mixed_case(lytspel):
                    mixed_dict[tradspell] = lytspel

            # TODO Add support for Redirects (2)
        return result


# Globals
mixed_dict = {}
ls_dict = load_dict()
nlp = spacy.load('en')


# Main code

def asciify(word: str) -> str:
    """Convert a word to its ASCII equivalent.

    Typographic apostrophes are replaced by normal ones and diacritical letters are
    replaced by their closest ASCII equivalents.
    """
    result = word.replace('’', "'")  # ASCII-ify apostrophes

    if not re.match("[a-zA-Z']*$", result): # non-ASCII word
        letters = list(result)

        for i, letter in enumerate(letters):
            if ord(letter) < 128: continue  # ASCII, nothing to do
            lower_letter = letter.lower()
            replacement = ''

            # vowels and semivowels
            if lower_letter in 'áàăâǎåäãąāả':
                replacement = 'a'
            elif lower_letter in 'æ':
                replacement = 'ae'
            elif lower_letter in 'éèĕêěëẽęēẻ':
                replacement = 'e'
            elif lower_letter in 'íìĭîǐïĩįī':
                replacement = 'i'
            elif lower_letter in 'óòŏôǒöõøǫōỏ':
                replacement = 'o'
            elif lower_letter in 'œ':
                replacement = 'oe'
            elif lower_letter in 'úùŭûǔůüũųūủ':
                replacement = 'u'
            elif lower_letter in 'ýỳŷẙÿỹȳỷ':
                replacement = 'y'
            # consonants
            elif lower_letter in 'ćĉčċç':
                replacement = 'c'
            elif lower_letter in 'ďđ':
                replacement = 'd'
            elif lower_letter in 'ǵğĝǧġḡ':
                replacement = 'g'
            elif lower_letter in 'ĥȟḧħ':
                replacement = 'h'
            elif lower_letter in 'ĵǰ':
                replacement = 'j'
            elif lower_letter in 'ḱǩ':
                replacement = 'k'
            elif lower_letter in 'ĺľłḹ':
                replacement = 'l'
            elif lower_letter in 'ḿ':
                replacement = 'm'
            elif lower_letter in 'ńǹňñ':
                replacement = 'n'
            elif lower_letter in 'ṕ':
                replacement = 'p'
            elif lower_letter in 'ŕř':
                replacement = 'r'
            elif lower_letter in 'śŝšş':
                replacement = 's'
            elif lower_letter in 'ß':
                replacement = 'ss'
            elif lower_letter in 'ťẗ':
                replacement = 't'
            elif lower_letter in 'ṽ':
                replacement = 'v'
            elif lower_letter in 'ẃẁẘẅ':
                replacement = 'w'
            elif lower_letter in 'ẍ':
                replacement = 'x'
            elif lower_letter in 'źẑž':
                replacement = 'z'

            if replacement:
                if letter != lower_letter:  #  original was upper case
                    replacement = replacement.upper()
                letters[i] = replacement

        result = ''.join(letters)
    return result


def translate_pos(spacy_pos: str) -> str:
    """Translate a POS tag as used by Spacy into the form used in the dictionary."""
    if spacy_pos in ('AUX', 'VERB'):
        return 'v'
    elif spacy_pos in ('NOUN', 'PROPN'):
        return 'n'
    elif spacy_pos == 'ADJ':
        return 'aj'
    elif spacy_pos == 'ADV':
        return 'av'
    elif spacy_pos == 'ADP':
        return 'prp'
    else:
        # Leave other tags as is (shouldn't occur regarding our POS-tagged entries)
        return spacy_pos


def find_pos_tagged_entry(entries: dict, spacy_pos: str) -> str:
    """Find the entry to use if several POS-tagged spellings exist for a word."""
    pos = translate_pos(spacy_pos)
    result = entries.get(pos)

    if result is None:
        # Try suitable fallbacks
        if pos in ('aj', 'av'):
            result = entries.get('v')
        elif pos == 'v':
            result = entries.get('aj')

    if result is None:
        # Use to last (alphabetically) entry as ultimate fallback
        warn("POS tag {} doesn't match any of the entries in {}; using last entry as fallback"
                .format(pos, entries))
        result = entries[sorted(entries.keys())[-1]]

    return result


def lookup(word: str, spacy_pos: str) -> str:
    """Lookup a word in the dictionary and returned its converted form.

    'spacy_pos' is the POS tag as returned by Spacy.

    Case is restored (lower, Capitalized, or ALL_CAPS). MixedCase is also restored
    provided that *both* the input word and the dictionary entry use this case form
    (e.g. JavaScript -> JaavaScript).
    """
    word = asciify(word)
    genitiveS = ''

    if re.search("'s$", word, re.IGNORECASE):
        # Strip final 's (genitive or contraction) and remember for later (handling case)
        genitiveS = word[-2:]
        word = word[:-2]

    result = ls_dict.get(word.lower())
    if result is None:
        return result

    if isinstance(result, dict):
        result = find_pos_tagged_entry(result, spacy_pos)

    if re.match("[A-Z']+$", word):
        result = result.upper()  # ALL_CAPS
    elif re.match('[A-Z]', word):
        if word in mixed_dict:
            result = mixed_dict[word]  #  MixedCase
        else:
            result = result[0].upper() + result[1:]  # Capitalized

    if genitiveS:
        result += genitiveS

    result = result.replace( "'", '’')  # replace normal by typographic apostrophe
    return result



def tokenize_text(text: str) -> List[str]:
    """Tokenize a string, returning an array of words and puncuation.

    Words must start and end with a letter and may contain apostrophes.
    """
    # TODO Obsolete??
    result = TOKEN_RE.split(text)
    # Remove first and/or last element if they are empty
    if result[0] == '':
        result.pop(0)
    if result[-1] == '':
        result.pop()
    return result


def is_word(token: str) -> bool:
    """Check if a token is a word. Words must start with a letter."""
    return STARTS_WITH_LETTER_RE.match(token)


def convert_para(text: str) -> str:
    """Convert a paragraph.

    If a large part of the words in the paragraph is unknown, it is assumed to be written
    in a foreign language and returned unchanged.
    """
    doc = nlp(text)
    tokens = []
    known_words = 0
    unknown_words = 0
    lasttok = ''

    for entry in doc:
        token = entry.text
        if token.lower() in ("n't", 'n’t'):
            # Spacy treats n't (as in don't etc.) as a separate word, but we look it up together
            # with the preceding word because the joined pronounciation (and hence spelling)
            # is sometimes different
            tokens.pop()
            token = lasttok + token

        if is_word(token):
            conv = lookup(token, entry.pos_)
            if conv:
                known_words += 1
                tokens.append(conv)
            else:
                unknown_words += 1
                tokens.append(token)
        else:
            # Not a word: append as is
            tokens.append(token)

        lasttok = token
        # Append trailing whitespace to token, if any
        if entry.whitespace_:
            tokens[-1] += entry.whitespace_

    if unknown_words <= known_words:
        # At least half of the words are known
        return ''.join(tokens)
    else:
        return text  # return text unchanged


def convert_file(filename: str) -> None:
    """Convert the file with the specified name."""
    para = ''

    with open(filename, 'r') as file:
        for line in file:
            line = line.rstrip()
            # Paragraphs are considered to be separated by empty lines.
            # However, very long lines (200+ chars) are considered paragraphs in their own right.
            if len(line) >= 200:  # stand-alone paragraph
                if para:
                    print(convert_para(para))
                    para = ''
                print(convert_para(line))
            elif line:            # regular line
                if para:
                    para += '\n'
                para += line
            else:                 # empty line
                print(convert_para(para))
                para = ''
                print()

        # Convert final paragraph, if any
        if para:
            print(convert_para(para))


if __name__ == '__main__':
    try:
        load_dict()
        for file in argv[1:]:
            convert_file(file)
    except Exception as e:
        error_desc = '{}: {}'.format(e.__class__.__name__, e)
        exit(error_desc)


# TODO Handle and test:
# * POS tags
# * Redirects
# * Also convert HTML (see below) and epub files; output in the latter case should be stored in
#   FILE-lytspel.epub
# * Special case: I and I'm should only remain capitalized at the beginning of sentences
# * Might require additional POS tag: ‹re› should become  «ri» if used as a hyphenated prefix
# * Might require additional POS tag: US (capitalized) should remain unchanged
# * Recognize URLs in text and treat as non-words (sample: IRC logs)
# * Use pylint to check the coding style
# * Add button to turn conversion off and on
# * Also rewrite parts of a page loaded later (e.g. due to scrolling; sample: Youtube
#   comments); possibly use a custom data-\* attribute; can be read and written as
#   elem.dataset.NAME, e.g. elem.dataset.lytspel = conv|seen
# * If called w/o arguments open dialog that allows the conversion of local txt/html/epub files,
#   always writing the output to a file
# * Add a dialog for converting words and sentences to Lytspel
# * Package for pip3 and announce to the world
# * Add drag-and-drop support (on Windows),

# const ATTRIBS_TO_CONVERT = ['alt', 'title'];
# const TAGS_TO_SKIP = ['script', 'style'];
# 
# // --- Primary helpers and callbacks ---
# 
# // Iterate the child nodes of an node. Element nodes are traversed recursively, while the
# // content of text nodes is tokenize and all word tokens are added to `wordset`.
# // Textual content of any ATTRIBS_TO_CONVERT is collected as well.
# function collectWordsFromChildNodes(node, wordset) {
#   // Collect from child nodes
#   for (const child of node.childNodes) {
#     switch(child.nodeType) {
#       case Node.ELEMENT_NODE:
#         if (! skipElement(child)) collectWordsFromChildNodes(child, wordset);
#         break;
#       case Node.TEXT_NODE:
#         collectWords(child.nodeValue, wordset);
#         break;
#     }
#   }
# 
#   // Collect from relevant attributes
#   for (const attrib of ATTRIBS_TO_CONVERT) {
#     collectWords(node.getAttribute(attrib), wordset);
#   }
# }
# 
# // Callback that converts the current document (including its title) to Lytspel.
# function convertToLytspel(words) {
#   convertChildNodes(document.body, words);
#   document.title = convertText(document.title, words);
# }
# 
# // Check whether an element should be skipped (consults the TAGS_TO_SKIP array).
# function skipElement(elem) {
#   return TAGS_TO_SKIP.includes(elem.tagName.lower());
# }
# 
# // Iterate the child nodes of an node. Element nodes are traversed recursively, while the
# // content of text nodes is converted to Lytspel. Textual content of any ATTRIBS_TO_CONVERT
# // is converted as well.
# function convertChildNodes(node, words) {
#   // Convert child nodes
#   for (const child of node.childNodes) {
#     switch(child.nodeType) {
#       case Node.ELEMENT_NODE:
#         if (! skipElement(child)) convertChildNodes(child, words);
#         break;
#       case Node.TEXT_NODE:
#         child.nodeValue = convertText(child.nodeValue, words);
#         break;
#     }
#   }
#   // Convert relevant attributes
#   for (const attrib of ATTRIBS_TO_CONVERT) {
#     if (! node.hasAttribute(attrib)) continue;  // Nothing to do
#     node.setAttribute(attrib, convertText(node.getAttribute(attrib), words));
#   }
# }
