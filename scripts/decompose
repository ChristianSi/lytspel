#!/usr/bin/perl -CA
# Recognize compounds and derived forms.
#
# Copyright (c) 2016-17 Christian Siefkes
# See accompanying LICENSE.txt file for licensing information.
#
# Required modules: Const::Fast and those listed in PhonEng.pm.

use 5.014;
use open qw(:std :utf8);  # use UTF-8 for all I/O (by default)
use utf8;                 # allow UTF-8 in source code
use warnings;

use Const::Fast;
use Cwd 'abs_path';
use File::Basename 'dirname';
use List::Util qw(any min max);

use lib dirname(abs_path $0);  # to locate the PhonEng package
use PhonEng;

const my $IN_FILE        => 'phonetic-dict.csv';
const my $OUT_FILE       => 'compounds.csv';
const my $MANUAL_ENTRIES => 'compounds-manual.csv';

# A CSV file containing blacklisted word parts that should NOT be considered part of a
# compound. If the second field is "1" or "2", the part is only blacklisted if it's the
# first/second element of a compound; otherwise it's blacklisted in either position.
const my $COMPOUND_BLACKLIST => 'compound-blacklist.csv';

# A whitelist of words that SHOULD be analysed as compounds even if their parts are blacklisted.
const my $COMPOUND_WHITELIST => 'compound-whitelist.csv';

const my $UNAMBIGUOUS_CONSONANTS => 'bcdfghjklmnpqrstvwxz';  # excluding 'y' (ambiguous)
const my $SHORT_VOWEL            => 'a#?|E|I#?|Q|V';         # excluding schwa and «oo» /U/
const my $NON_SCHWA_VOWEL => 'a[#IU]?|A|E|eI|I#?|i:|O[:I]|oU|Q|U|u:|V';

my $CSV_IN  = new_csv_in;
my $CSV_OUT = new_csv_out;

# build_dict: Return a reference to a list of all words in the dict. Words (keys) are converted
# to lower-case; values are set to an array of references of the three pronunciatons.
# If a word is listed several times (with different POS tags, e.g. "house"), all of its
# pronunciations are combined. Single-letter words and redirects are skipped.
sub build_dict {
    open my $file, '<', $IN_FILE or die "Unable to open $IN_FILE: $!\n";
    my $colref = $CSV_IN->getline($file);  # skip header line
    my %dict;

    while ($colref = $CSV_IN->getline($file)) {
        next if scalar @$colref < 4;       # skip redirects
        my $word = lc $colref->[0];
        my @prons = splice @$colref, 3;

        if (length $word > 1) {
            my $oldval = $dict{$word};

            if ($oldval) {
                push @$oldval, @prons;
            } else {
                $dict{$word} = \@prons;
            }
        }
    }

    close $file;
    return \%dict;
}

# build_affix_set $filename: Build a set of affixes (pre- or suffixes).
# Returns a reference to a set of affixes (a hash with dummy values).
# Also returns the minimun and maximum affix length.
sub build_affix_set {
    my ($filename) = @_;
    my %prefix_set;
    my $min_prefix_len = 1000;
    my $max_prefix_len = 0;

    open my $file, '<', $filename or die "Unable to open $filename: $!\n";

    while (my $line = <$file>) {
        chomp $line;
        $prefix_set{$line} = 1;
        my $len = length $line;
        $min_prefix_len = min $min_prefix_len, $len;
        $max_prefix_len = max $max_prefix_len, $len;
    }

    close $file;
    return \%prefix_set, $min_prefix_len, $max_prefix_len;
}

# Build a list of manual entries from the $MANUAL_ENTRIES CSV file. All entries in this
# file will be used as is, except that both keys and values are converted to lower case.
# If the second field is empty, they will be skipped altogether (not considered as compounds).
sub build_manual_entries_dict {
    open my $file, '<', $MANUAL_ENTRIES or die "Unable to open $MANUAL_ENTRIES: $!\n";
    my $colref = $CSV_IN->getline($file);  # skip header line
    my %dict;

    while ($colref = $CSV_IN->getline($file)) {
        my $word = lc $colref->[0];
        $dict{$word} = lc($colref->[1] // '');
    }

    close $file;
    return \%dict;
}

# Build black and white lists to refine compound detection. Returns references to three sets:
#
# 1. A black list of parts that are not allowed as first part of a compound.
# 2. A black list of parts that are not allowed as second part of a compound.
# 3. A white list of words that should nevertheless be recognized as compounds, ignoring the
#    black list.
sub build_black_and_white_list {
    # Create blacklists
    open my $file, '<', $COMPOUND_BLACKLIST or die "Unable to open $COMPOUND_BLACKLIST: $!\n";
    my $colref = $CSV_IN->getline($file);  # skip header line
    my %blacklist1;
    my %blacklist2;

    while ($colref = $CSV_IN->getline($file)) {
        my $word = $colref->[0];
        my $pos = $colref->[1] // '';
        die "Blacklist entry '$word' has invalid position '$pos'\n" unless $pos =~ /^[12]?$/;
        $blacklist1{$word} = 1 unless $pos eq 2;
        $blacklist2{$word} = 1 unless $pos eq 1;
    }

    close $file;

    # Create whitelist
    open $file, '<', $COMPOUND_WHITELIST or die "Unable to open $COMPOUND_WHITELIST: $!\n";
    $colref = $CSV_IN->getline($file);  # skip header line
    my %whitelist;

    while ($colref = $CSV_IN->getline($file)) {
        my $word = $colref->[0];
        $whitelist{$word} = 1;
    }

    close $file;
    return \%blacklist1, \%blacklist2, \%whitelist;
}

# discard_empty_elements_and_normalize $arr_ref: Discard empty, undefined, or duplicate elements
# from the passed-in array reference, returning those that remain. Also normalizes each element as
# follows:
#
# * All stress markers are removed (since stress often moves in derived words)
# * '#' is removed (since it only marks a vowel variant)
# * As alternative variant in which all stressed short vowels (except special r-colored vowels) are
#   replaced by a schwa is added to the result array (since stress often moves in derived words and
#   a stressed short vowel may be reduced to a schwa or vice versa) -- to prevent spurious matches,
#   this alternative is only added if it at least one non-schwa vowel remains
#
# The alternative variants allow the recognition of derived words such "hexagonal" (hexagon=al).
sub discard_empty_elements_and_normalize {
    my ($arr_ref) = @_;
    my %result_set;

    for my $pron (@$arr_ref) {
        next unless $pron;  # Skip empty entries

        # Create schwa-ified alternative
        my $altpron = $pron =~ s/'($SHORT_VOWEL)/@/gr;
        $altpron =~ s/['#]//g;  # Remove stress markers and '#'
        $result_set{$altpron} = 1 if $altpron =~ /$NON_SCHWA_VOWEL/;
        $pron =~ s/['#]//g;     # Remove stress markers and '#'
        $result_set{$pron} = 1;
    }

    return keys %result_set;
}

# build_combined_pattern $first_prons_aref, $second_prons_aref: Build a combined matching
# pattern from two lists of pronunciations for the parts of a compound (two array references).
sub build_combined_pattern {
    my ($first_prons_aref, $second_prons_aref) = @_;
    my $second_start_chars = '';

    # Allow subsequent /r/ if pron ends in /`/ (e.g. "after-hours")
    s/`$/`r?/ for @$first_prons_aref;

    my $first_pattern = '^(' . join('|', @$first_prons_aref) . ')';
    my $second_pattern = '(' . join('|', @$second_prons_aref) . ')$';
    return "$first_pattern$second_pattern";
}

# prons_match $first, $second, $word, $dict_ref: Return true (1) if at least one of the
# pronunciations of $word starts with one of the pronunciations of $first and ends with one of the
# pronunciations of $second. Returns false (0) otherwise.
# This filters out apparent compounds and derived forms which aren't pronounced as an actual
# compound would be.
# If $first or $second is empty, only the other part is checked -- that's useful for affixes
# (which aren't always listed in the dict and may be spoken differently in some cases).
sub prons_match {
    my ($first, $second, $word, $dict_ref) = @_;
    my @word_prons = discard_empty_elements_and_normalize $dict_ref->{$word};
    my @first_prons;
    my @second_prons;
    my $first_check_ok  = 1;
    my $second_check_ok = 1;

    if ($first) {
        @first_prons = discard_empty_elements_and_normalize $dict_ref->{$first};
        my $first_pattern = '^(' . join('|', @first_prons) . ')';
        $first_check_ok = any { /$first_pattern/ } @word_prons;
    }

    if ($first_check_ok && $second) {
        @second_prons = discard_empty_elements_and_normalize $dict_ref->{$second};
        my $second_pattern = '(' . join('|', @second_prons) . ')$';

        if ($first) {
            # Check whether full pronunciation matches
            my $combined_pattern = build_combined_pattern \@first_prons, \@second_prons;
            $second_check_ok = any { /$combined_pattern/ } @word_prons;
        } else {
            $second_check_ok = any { /$second_pattern/ } @word_prons;
        }
    }

    return $first_check_ok && $second_check_ok;
}

# valid_entry ...: Check whether an entry is valid. If checking for prefixed or suffixed
# words, $first or $second (respectively) should be set to an empty string, otherwise
# both should be set.
sub valid_entry {
    my ($word, $first, $second, $dict_ref, $blacklist1_ref, $blacklist2_ref, $whitelist_ref) = @_;
    # Check that $first and $second (if specified) are listed in the dictionary
    my $valid = !$first || exists $dict_ref->{$first};
    $valid &&= !$second || $dict_ref->{$second};

    unless (exists $whitelist_ref->{$word}) {
        # Unless the whole word is whitelisted, check that none of the specified parts
        # is blacklisted
        $valid &&= !($first  && exists $blacklist1_ref->{$first});
        $valid &&= !($second && exists $blacklist2_ref->{$second});
    }

    # Check that pronunciations match
    $valid &&= prons_match $first, $second, $word, $dict_ref;
    return $valid;
}

# analyze_as_prefixed_form ...: Check whether $word is the prefixed form of another word in
# $dict_ref. Returns a result of the form "prefix=stem" if a match was found, undef otherwise.
# When in doubt, longer prefixes are preferred over shorter ones.
sub analyze_as_prefixed_form {
    my (
        $word,           $dict_ref,       $prefix_set_ref, $min_prefix_len,
        $max_prefix_len, $blacklist1_ref, $blacklist2_ref, $whitelist_ref
    ) = @_;

    for (my $i = min($max_prefix_len, length($word) - 2) ; $i >= $min_prefix_len ; $i--) {
        my $prefix = substr $word, 0, $i;
        my $stem = substr $word, $i;

        if (exists $prefix_set_ref->{$prefix} && valid_entry $word,
            '', $stem, $dict_ref, $blacklist1_ref, $blacklist2_ref, $whitelist_ref)
        {
            return "$prefix=$stem";
        }
    }

    return undef;
}

# valid_suffix $stem, $suffix: Check whether a suffix is valid. It's not if it has just a
# single letter and would split a final double letter (such as ‹nn› or ‹ss›) in half.
sub valid_suffix {
    my ($stem, $suffix) = @_;
    return length($suffix) != 1 || substr($stem, -1) ne $suffix;
}

# find_alternative_base $stem: Return an alternative base form of $stem. Generates one of the
# following alternatives:
#
# * A repeated final consonant (excluding 'y') is dropped, e.g. 'acquitt' becomes 'acquit'
# * Final 'ck' becomes 'c', e.g. 'panick' becomes 'panic'
# * Otherwise 'e' is appended after a final consonant, e.g. 'judg' becomes 'judge'
# * Final 'i' after a consonant becomes 'y', e.g. 'happi' becomes 'happy'
#
# Otherwise undef is returned.
sub find_alternative_base {
    my ($stem) = @_;

    if ($stem =~ /([$UNAMBIGUOUS_CONSONANTS])\1$/ || $stem =~ /ck$/) {
        chop $stem;
        return $stem;
    } elsif ($stem =~ /([$UNAMBIGUOUS_CONSONANTS])$/) {
        return $stem . 'e';
    } elsif ($stem =~ /([$UNAMBIGUOUS_CONSONANTS])i$/) {
        chop $stem;
        return $stem . 'y';
    } else {
        return undef;
    }
}

# analyze_as_suffixed_form ...: Check whether $word is the suffixed form of another word in
# $dict_ref. Returns a result of the form "stem=suffix" if a match was found, undef otherwise.
# When in doubt, shorter suffixes are preferred over longer ones.
# Stem changes in words such as ‹running› (run=ing) and ‹happiness› (happy=ness) are taken into
# account.
sub analyze_as_suffixed_form {
    my (
        $word,           $dict_ref,       $suffix_set_ref, $min_suffix_len,
        $max_suffix_len, $blacklist1_ref, $blacklist2_ref, $whitelist_ref
    ) = @_;
    my $len = length $word;
    my $max_len = min($max_suffix_len, $len - 2);

    for (my $i = $min_suffix_len ; $i <= $max_len ; $i++) {
        my $suffix_start = $len - $i;
        my $stem         = substr $word, 0, $suffix_start;
        my $suffix       = substr $word, $suffix_start;

        if (exists $suffix_set_ref->{$suffix}) {
            if (
                valid_entry(
                    $word,           $stem,           '', $dict_ref,
                    $blacklist1_ref, $blacklist2_ref, $whitelist_ref
                )
                && valid_suffix($stem, $suffix)
                )
            {
                if ($suffix eq 'an' && $stem =~ /[^e]e$/ && exists $suffix_set_ref->{'ean'}) {
                    # Prefer 'ean' (if listed) over 'an' if the stem ends in silent 'e',
                    # e.g. ‹argentinean› become 'argentine=ean'
                    return "$stem=ean";
                } else {
                    return "$stem=$suffix";
                }
            }

            # Check whether a match can be found by taking stem changes such as ‹running›
            # (run=ing), ‹judgment› (judge=ment), and ‹happiness› (happy=ness) into account
            my $alternative_base = find_alternative_base $stem;

            if ($alternative_base && valid_entry $word,
                $alternative_base, '', $dict_ref, $blacklist1_ref, $blacklist2_ref, $whitelist_ref)
            {

                if (length($alternative_base) < length($stem)) {
                    # If the alternative stem is shorter, check whether the rest of the
                    # word forms a more suitable suffix (preferring e.g. "ly" over "y",
                    # "less/ness" over "ess"
                    my $alt_suffix = substr $word, length($alternative_base);
                    return "$alternative_base=$alt_suffix" if exists $suffix_set_ref->{$alt_suffix};
                }

                return "$alternative_base=$suffix";
            }
        }
    }

    return undef;
}

# prefer_new_match $first, $second, $new_first, $new_second: Return true-ish iff the new match
# ($new_first-$new_second) should be preferred over the old one ($first-$second).
# Prefers the pair whose variants are more similar to each other in length (a split into a
# 4-letter and a 3-letter word will be preferred over one into a 5-letter and a 2-letter word).
# In case of the tie, the new match is chosen if it doesn't split a double letter, while
# the old one does (e.g. ‹sell-out› instead of ‹sel-lout›).
# Otherwise, the old match is chosen (e.g. ‹ear-plug› instead of ‹earp-lug›).
sub prefer_new_match {
    my ($first, $second, $new_first, $new_second) = @_;
    my $old_dist = abs(length($first) - length($second));
    my $new_dist = abs(length($new_first) - length($new_second));

    if ($new_dist < $old_dist) {
        return 1;
    } elsif ($new_dist == $old_dist) {
        return substr($first,     -1) eq substr($second,     0, 1)
            && substr($new_first, -1) ne substr($new_second, 0, 1);
    } else {
        return 0;
    }
}

# check_for_better_match $length_of_first_part, $word, $prev_first, $prev_second, $dict_ref ...:
# Splits word into a compound pair according to $length_of_first_part.
# If both parts of the pair exist in $dict_ref and if their joined pronunciation matches that
# of $word, then the new pair is returned if it seems to be a better match than the previously
# best pair specified by $prev_first, $prev_second.
# If there is no new pair, the old pair is returned.
# If the old pair is empty (= none found yet), the new pair is returned.
# Otherwise the algorithm documented in 'prefer_new_match' is used.
sub check_for_better_match {
    my ($length_of_first_part, $word, $first, $second, $dict_ref, $blacklist1_ref,
        $blacklist2_ref, $whitelist_ref)
        = @_;
    my $new_first = substr $word, 0, $length_of_first_part;
    my $new_second = substr $word, $length_of_first_part;

    if (valid_entry $word,
        $new_first, $new_second, $dict_ref, $blacklist1_ref, $blacklist2_ref, $whitelist_ref)
    {
        if ($first) {
            if (prefer_new_match $first, $second, $new_first, $new_second) {
                $first  = $new_first;
                $second = $new_second;
            }
        } else {
            $first  = $new_first;
            $second = $new_second;
        }
    }

    return $first, $second;
}

# find_parts ...: Check if the word seems to be a compound or a derived form and add a suitable
# entry to the output file if it does.
#
# Separators used:
#
# * '-' between parts of a compound
# * '=' after a prefix and before a suffix
sub find_parts {
    my (
        $outfh,          $word,               $dict_ref,       $prefix_set_ref,
        $min_prefix_len, $max_prefix_len,     $suffix_set_ref, $min_suffix_len,
        $max_suffix_len, $manual_entries_ref, $blacklist1_ref, $blacklist2_ref,
        $whitelist_ref
    ) = @_;
    my $len = length $word;

    # Use manual entries, if any
    my $manual_val = $manual_entries_ref->{$word};
    if (defined $manual_val) {
        # Use the manual entry unless it's empty (then the word is skipped altogether)
        $CSV_OUT->print($outfh, [$word, $manual_val]) if $manual_val;
        return;
    }

    return if $len < 4;  # too short to be a compound

    # Check whether it's a prefixed or suffixed form
    my $result = analyze_as_prefixed_form $word, $dict_ref, $prefix_set_ref, $min_prefix_len,
        $max_prefix_len, $blacklist1_ref, $blacklist2_ref, $whitelist_ref;
    $result = analyze_as_suffixed_form $word, $dict_ref, $suffix_set_ref, $min_suffix_len,
        $max_suffix_len, $blacklist1_ref, $blacklist2_ref, $whitelist_ref
        unless $result;

    if ($result) {
        $CSV_OUT->print($outfh, [$word, $result]);
        return;
    }

    my $first  = '';
    my $second = '';

    # Check whether it's a compound of two words
    for my $i (3 .. $len - 3) {
        ($first, $second) = check_for_better_match $i, $word, $first, $second, $dict_ref,
            $blacklist1_ref, $blacklist2_ref, $whitelist_ref;
    }

    if ($first) {
        $CSV_OUT->print($outfh, [$word, "$first-$second"]);
    }
}

# decompose: Recognize compounds and derived forms.
sub decompose {
    my $dict_ref = build_dict;
    my ($prefix_set_ref, $min_prefix_len, $max_prefix_len) = build_affix_set 'prefix.list';
    my ($suffix_set_ref, $min_suffix_len, $max_suffix_len) = build_affix_set 'suffix.list';
    my $manual_entries_ref = build_manual_entries_dict;
    my ($blacklist1_ref, $blacklist2_ref, $whitelist_ref) = build_black_and_white_list;
    my $outfh = open_outfile_and_write_header $OUT_FILE, [qw(Word Parts)];
    find_parts $outfh, $_, $dict_ref, $prefix_set_ref, $min_prefix_len, $max_prefix_len,
        $suffix_set_ref, $min_suffix_len, $max_suffix_len, $manual_entries_ref,
        $blacklist1_ref, $blacklist2_ref, $whitelist_ref
        for sort { lc $a cmp lc $b } keys %$dict_ref;
    close $outfh;
}

# Main block
decompose;
